wandb_version: 1

_wandb:
  desc: null
  value:
    cli_version: 0.10.30
    code_path: code/curriculum_code/task_difficulty_experiment_mujoco.py
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    python_version: 3.8.5
    t:
      1:
      - 1
      - 5
      2:
      - 1
      - 5
      3:
      - 1
      4: 3.8.5
      5: 0.10.30
      8:
      - 3
      - 5
num_tasks:
  desc: null
  value: 100
steps_per_task:
  desc: null
  value: 500
student:
  desc: null
  value: <stable_baselines3.ppo.ppo.PPO object at 0x0000016F51CFDD90>
student_params:
  desc: null
  value:
    _current_progress_remaining: 1
    _episode_num: 0
    _last_dones: null
    _last_obs: null
    _last_original_obs: null
    _n_updates: 0
    _total_timesteps: 0
    _vec_normalize_env: null
    action_noise: null
    action_space: Box(-2.0, 2.0, (1,), float32)
    batch_size: 64
    clip_range: stable_baselines3.common.utils.constant_fn.<locals>.func
    clip_range_vf: null
    device: cuda
    ent_coef: 0.0
    env: <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x0000016F51CFDF10>
    ep_info_buffer: null
    ep_success_buffer: null
    eval_env: null
    gae_lambda: 0.95
    gamma: 0.99
    learning_rate: 0.0003
    lr_schedule: stable_baselines3.common.utils.constant_fn.<locals>.func
    max_grad_norm: 0.5
    n_envs: 1
    n_epochs: 10
    n_steps: 125
    num_timesteps: 0
    observation_space: Box(-8.0, 8.0, (5,), float32)
    policy: "ActorCriticPolicy(\n  (features_extractor): FlattenExtractor(\n    (flatten):\
      \ Flatten(start_dim=1, end_dim=-1)\n  )\n  (mlp_extractor): MlpExtractor(\n\
      \    (shared_net): Sequential()\n    (policy_net): Sequential(\n      (0): Linear(in_features=5,\
      \ out_features=8, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=8,\
      \ out_features=8, bias=True)\n      (3): Tanh()\n    )\n    (value_net): Sequential(\n\
      \      (0): Linear(in_features=5, out_features=8, bias=True)\n      (1): Tanh()\n\
      \      (2): Linear(in_features=8, out_features=8, bias=True)\n      (3): Tanh()\n\
      \    )\n  )\n  (action_net): Linear(in_features=8, out_features=1, bias=True)\n\
      \  (value_net): Linear(in_features=8, out_features=1, bias=True)\n)"
    policy_class: stable_baselines3.common.policies.ActorCriticPolicy
    policy_kwargs:
      net_arch:
      - pi:
        - 8
        - 8
        vf:
        - 8
        - 8
    rollout_buffer: <stable_baselines3.common.buffers.RolloutBuffer object at 0x0000016F51CE1F10>
    sde_sample_freq: -1
    seed: null
    start_time: null
    target_kl: null
    tensorboard_log: null
    use_sde: false
    verbose: 0
    vf_coef: 0.5
task:
  desc: null
  value: MBPendulum-v2
teacher:
  desc: null
  value: <curriculum.teachers.predefined_tasks_teacher.PredefinedTasksTeacher object
    at 0x0000016F4CC592B0>
teacher_params:
  desc: null
  value:
    env_wrapper: <environment.parametric_mujoco.parametric_pendulum_locomotion.MBPendulumAngleContinuousWrapper
      object at 0x0000016F4CC59340>
    eval_data: []
    history: <curriculum.history.History object at 0x0000016F4CC59250>
    idx: 0
    seed: null
    tasks_to_cycle:
    - goal_angle: 3.141592653589793
    - goal_angle: 1.5707963267948966
    - goal_angle: 1.0471975511965976
    - goal_angle: 0.7853981633974483
    - goal_angle: 0.6283185307179586
    - goal_angle: 0.5235987755982988
    - goal_angle: 0.4487989505128276
    - goal_angle: 0.39269908169872414
    - goal_angle: 0.3490658503988659
    - goal_angle: 0.3141592653589793
    - goal_angle: 0.28559933214452665
    - goal_angle: 0.2617993877991494
    - goal_angle: 0.24166097335306103
    - goal_angle: 0.2243994752564138
    - goal_angle: 0.20943951023931953
    - goal_angle: 0.19634954084936207
    - goal_angle: 0.18479956785822313
    - goal_angle: 0.17453292519943295
    - goal_angle: 0.16534698176788384
    - goal_angle: 0.15707963267948966
    - goal_angle: 0.1495996501709425
    - goal_angle: 0.14279966607226333
    - goal_angle: 0.13659098493868665
    - goal_angle: 0.1308996938995747
    - goal_angle: 0.12566370614359174
    - goal_angle: 0.12083048667653051
    - goal_angle: 0.11635528346628862
    - goal_angle: 0.1121997376282069
    - goal_angle: 0.10833078115826873
    - goal_angle: 0.10471975511965977
    - goal_angle: 0.10134169850289655
    - goal_angle: 0.09817477042468103
    - goal_angle: 0.09519977738150888
    - goal_angle: 0.09239978392911156
    - goal_angle: 0.08975979010256552
    - goal_angle: 0.08726646259971647
    - goal_angle: 0.0849079095564809
    - goal_angle: 0.08267349088394192
    - goal_angle: 0.08055365778435367
    - goal_angle: 0.07853981633974483
    - goal_angle: 0.07662421106316569
    - goal_angle: 0.07479982508547126
    - goal_angle: 0.07306029426953008
    - goal_angle: 0.07139983303613166
    - goal_angle: 0.06981317007977318
    - goal_angle: 0.06829549246934333
    - goal_angle: 0.06684239688488922
    - goal_angle: 0.06544984694978735
    - goal_angle: 0.0641141357875468
    - goal_angle: 0.06283185307179587
    - goal_angle: 0.06159985595274104
    - goal_angle: 0.060415243338265257
    - goal_angle: 0.059275333086599866
    - goal_angle: 0.05817764173314431
    - goal_angle: 0.057119866428905326
    - goal_angle: 0.05609986881410345
    - goal_angle: 0.05511566058929461
    - goal_angle: 0.054165390579134366
    - goal_angle: 0.05324733311169141
    - goal_angle: 0.05235987755982988
    - goal_angle: 0.05150151891130809
    - goal_angle: 0.050670849251448276
    - goal_angle: 0.04986655005698084
    - goal_angle: 0.04908738521234052
    - goal_angle: 0.04833219467061221
    - goal_angle: 0.04759988869075444
    - goal_angle: 0.046889442590892436
    - goal_angle: 0.04619989196455578
    - goal_angle: 0.04553032831289555
    - goal_angle: 0.04487989505128276
    - goal_angle: 0.04424778385337737
    - goal_angle: 0.04363323129985824
    - goal_angle: 0.04303551580259991
    - goal_angle: 0.04245395477824045
    - goal_angle: 0.04188790204786391
    - goal_angle: 0.04133674544197096
    - goal_angle: 0.04079990459207524
    - goal_angle: 0.04027682889217683
    - goal_angle: 0.03976699561506067
    - goal_angle: 0.039269908169872414
    - goal_angle: 0.038785094488762877
    - goal_angle: 0.038312105531582846
    - goal_angle: 0.03785051389867221
    - goal_angle: 0.03739991254273563
    - goal_angle: 0.036959913571644624
    - goal_angle: 0.03653014713476504
    - goal_angle: 0.036110260386089575
    - goal_angle: 0.03569991651806583
    - goal_angle: 0.03529879386055947
    - goal_angle: 0.03490658503988659
    - goal_angle: 0.03452299619329443
    - goal_angle: 0.034147746234671664
    - goal_angle: 0.033780566167632184
    - goal_angle: 0.03342119844244461
    - goal_angle: 0.033069396353576766
    - goal_angle: 0.032724923474893676
    - goal_angle: 0.032387553129791684
    - goal_angle: 0.0320570678937734
    - goal_angle: 0.03173325912716963
    - goal_angle: 0.031415926535897934
